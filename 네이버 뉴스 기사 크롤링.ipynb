{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집\n",
    "네이버 뉴스 기사 사회면 헤드라인 웹크롤링 <br/>\n",
    "출처: https://news.naver.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num():\n",
    "    print(\"##########################################\")\n",
    "    num = int(input(\"원하는 숫자를 입력해주세요.\"))\n",
    "    print(\"##########################################\")\n",
    "    return num\n",
    "\n",
    "def news_crawling():\n",
    "    ######### 네이버 url 가져올때, hearder을 안주는 경우 오류 발생시 ############\n",
    "    headers = {\n",
    "    \"User-Agent\":\n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) \\\n",
    "    Chrome/44.0.2403.157 Safari/537.36\"\n",
    "    }\n",
    "    print(\"############# 네이버 뉴스 헤드라인 웹 크롤링 시작 ############\")\n",
    "    ### 네이버 뉴스 메인 페이지에서 상단바에서 뉴스 토픽을 설정해서 해당 토픽의 'a' 태그로 이동\n",
    "    r = requests.get('https://news.naver.com/', headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    for title in range(len(soup.find(\"ul\",'Nlnb_menu_list').find_all('li')[1:-4])):\n",
    "        print(title+1 ,'', soup.find(\"ul\",'Nlnb_menu_list').find_all('li')[1:-4][title].text)\n",
    "    title_num = num() # title 선택\n",
    "    title = soup.find(\"ul\",'Nlnb_menu_list').find_all('li')[title_num].text # 나중에 데이터 저장하기 위해서 \n",
    "    url = soup.find(\"ul\",'Nlnb_menu_list').find_all('li')[title_num].find('a')['href']\n",
    "    \n",
    "    ### 이동된 세부 뉴스 토픽 페이지에서 왼쪽 사이드 바에서 세부 토픽 선택 후 해당 'a' 태그로 이동\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    for topic in range(len(soup.find('div',id='snb').find_all('li'))):\n",
    "        print(topic+1 ,'', soup.find('div',id='snb').find_all('li')[topic].text)    \n",
    "    topic_num = num()\n",
    "    \n",
    "    # a 태그로 이동하지 않고 / 한글을 입력하면 전체 뉴스 기사가 나옴\n",
    "    a = int(input(\"요약본 1번 / 전체본 2번 선택해주세요.\"))\n",
    "    if a == 1:\n",
    "        minor_topic = soup.find('div',id='snb').find_all('li')[topic_num-1].find('a')['href'].split('&')[-1]\n",
    "    else:\n",
    "        minor_topic = soup.find('div',id='snb').find_all('li')[topic_num-1].text\n",
    "    minor_topic1 = soup.find('div',id='snb').find_all('li')[topic_num-1].text # 나중에 데이터 저장할때 쓰기위함\n",
    "    \n",
    "    news_list = []\n",
    "    date_list = []\n",
    "    # 중간에 url이 main에서 list로 바껴야함\n",
    "    news_url = url+'&'+minor_topic\n",
    "    news_url = news_url.split('main.')[0]+'list.'+news_url.split('main.')[1]\n",
    "    news_url = news_url.replace('LSD','LS2D') \n",
    "    print(news_url)\n",
    "    \n",
    "    ###################### 날짜 입력하는 부분은 안배움 ############################\n",
    "    ###################### 밑 날짜 데이터 다루기 예시 참조 ########################\n",
    "    print(\"##########################################\")\n",
    "    print('뉴스 크롤링을 시작할 날짜를 입력해주세요.')\n",
    "    start = input(\"예: 20200101\")\n",
    "    print('뉴스 크롤링을 끝낼 날짜를 입력해주세요.')\n",
    "    end = input(\"예: 20200101\")\n",
    "    print(\"##########################################\")\n",
    "    start = datetime.datetime.strptime(start, \"%Y%m%d\")\n",
    "    end = datetime.datetime.strptime(end, \"%Y%m%d\")\n",
    "    period = end-start\n",
    "    date_generated = pd.date_range(start,periods=period.days)\n",
    "    ###############################################################################\n",
    "    \n",
    "    # 날짜 별로 이동하기 위한 for문\n",
    "    for date in range(len(date_generated)):\n",
    "        r = requests.get(news_url+'&date='+str(date_generated[date].strftime(\"%Y%m%d\")), headers=headers)\n",
    "        print(news_url+'&date='+str(date_generated[date].strftime(\"%Y%m%d\")))\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        # 끝 페이지를 알기위해서 임의의 높은 숫자를 입력하면 맨 끝 페이지로 이동 [실제 10000번째가 있으면 끝 아닐 수 있음]\n",
    "        s = requests.get(news_url+'&date='+str(date_generated[date].strftime(\"%Y%m%d\"))+\n",
    "                         '&page=100000', headers=headers)\n",
    "        s_soup = BeautifulSoup(s.text, 'html.parser')\n",
    "        page_num = int(s_soup.find('div','paging').find('strong').text)\n",
    "        ###### tqdm()을 for문에 사용하면 for문이 돌아가는 것을 시각화 할 수 있음.\n",
    "        ## 페이지를 넘기는 부분\n",
    "        for j in tqdm(range(page_num),desc=date_generated[date].strftime(\"%Y%m%d\")):\n",
    "            r = requests.get(news_url+'&date='+str(date_generated[date].strftime(\"%Y%m%d\")+\n",
    "                             '&page='+str(j+1)), headers=headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            # 각 페이지 마다 기사를 가져오기 위한 부분\n",
    "            for i in range(len(soup.find('div','list_body newsflash_body').find_all('li'))):\n",
    "                date_list.append(date_generated[date].strftime(\"%Y%m%d\"))\n",
    "                news_list.append(soup.find('div','list_body newsflash_body').find_all('li')[i].find_all('a')[-1].text.strip())\n",
    "    \n",
    "    # 데이터 프레임으로 저장\n",
    "    df = pd.DataFrame({\"날짜\":date_list,\"헤드라인\":news_list})\n",
    "    \n",
    "    # 데이터 프레임 이름 설정에 / 가 있으면 경로 오류가 생김으로 변경\n",
    "    if '/' in minor_topic1 or '/' in title:\n",
    "        title = title.replace('/','')\n",
    "        minor_topic1 = minor_topic1.replace('/','')\n",
    "        \n",
    "    # 데이터 저장하기 [경로 맞게 지정해주기]\n",
    "    df.to_csv('dataset/네이버뉴스_'+title+'_'+minor_topic1+'.csv',encoding='utf-8-sig')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# 네이버 뉴스 헤드라인 웹 크롤링 시작 ############\n",
      "1  정치\n",
      "2  경제\n",
      "3  사회\n",
      "4  생활/문화\n",
      "5  IT/과학\n",
      "6  세계\n",
      "7  랭킹\n",
      "##########################################\n",
      "원하는 숫자를 입력해주세요.3\n",
      "##########################################\n",
      "1  사건사고 \n",
      "2  교육 \n",
      "3  노동 \n",
      "4  언론 \n",
      "5  환경 \n",
      "6  인권/복지 \n",
      "7  식품/의료 \n",
      "8  지역 \n",
      "9  인물 \n",
      "10  사회 일반 \n",
      "##########################################\n",
      "원하는 숫자를 입력해주세요.6\n",
      "##########################################\n",
      "요약본 1번 / 전체본 2번 선택해주세요.1\n",
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b\n",
      "##########################################\n",
      "뉴스 크롤링을 시작할 날짜를 입력해주세요.\n",
      "예: 2020010120220320\n",
      "뉴스 크롤링을 끝낼 날짜를 입력해주세요.\n",
      "예: 2020010120220325\n",
      "##########################################\n",
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b&date=20220320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20220320: 100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  6.19it/s]\n",
      "20220321:   0%|                                                                                  | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b&date=20220321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20220321: 100%|██████████████████████████████████████████████████████████████████████████| 9/9 [00:01<00:00,  6.20it/s]\n",
      "20220322:   0%|                                                                                  | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b&date=20220322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20220322: 100%|██████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  6.05it/s]\n",
      "20220323:   0%|                                                                                 | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b&date=20220323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20220323: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=102&sid2=59b&date=20220324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20220324: 100%|██████████████████████████████████████████████████████████████████████████| 9/9 [00:01<00:00,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "df = news_crawling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 날짜 데이터 다루기 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 문자열 20200111 을 날짜 형식에 맞춰서 년도/월/일로 변환\n",
    "start = datetime.datetime.strptime('20200111', \"%Y%m%d\")\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start변수에는 날짜 타입\n",
    "type(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-11 00:00:00\n"
     ]
    }
   ],
   "source": [
    "end = datetime.datetime.strptime('20200211', \"%Y%m%d\")\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜 끼리 연산\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜 연산에서 빼진 날만 구하기\n",
    "(end - start).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14',\n",
       "               '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18',\n",
       "               '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22',\n",
       "               '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26',\n",
       "               '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30',\n",
       "               '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03',\n",
       "               '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07',\n",
       "               '2020-02-08', '2020-02-09', '2020-02-10'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 해당 날짜 기간동안 날짜 데이터 레인지 생성\n",
    "date_generated = pd.date_range(start, periods= (end - start).days)\n",
    "date_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
